{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "da93c3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root added to sys.path: /Users/connorplaks/rl-ga-travelin-salesman\n",
      "TSPLIBLoader imported and loader created (data/problem_instances)\n"
     ]
    }
   ],
   "source": [
    "# Ensure repo root is on sys.path and `data/` can be imported reliably\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "\n",
    "# Locate project root by walking up until we find a `data/` directory\n",
    "p = Path.cwd()\n",
    "while not (p / 'data').exists() and p.parent != p:\n",
    "    p = p.parent\n",
    "repo_root = p\n",
    "\n",
    "# Add repo root to sys.path so `import data` works\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "print(f\"Repo root added to sys.path: {repo_root}\")\n",
    "\n",
    "# Use the correct class name: TSPLIBLoader (capital B)\n",
    "from data.tsplib_loader import TSPLIBLoader\n",
    "loader = TSPLIBLoader(data_dir=str(repo_root / \"data\" / \"problem_instances\"))\n",
    "print(\"TSPLIBLoader imported and loader created (data/problem_instances)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011fb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading instance: eil51\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from data.tsplib_loader import TSPLIBLoader\n",
    "loader = TSPLIBLoader(data_dir=\"../../data/problem_instances\")\n",
    "instances = ['eil51', 'berlin52', 'st70', 'eil76', 'kroA100', 'pr107']\n",
    "instances = ['eil51', 'berlin52', 'st70', 'eil76', 'kroA100', 'pr107']\n",
    "test_instance_idx = 0\n",
    "instance = instances[test_instance_idx]\n",
    "print(f\"Loading instance: {instance}\")\n",
    "# Load instance\n",
    "data = loader.load_instance('eil51')\n",
    "\n",
    "# Load optimal tour\n",
    "tour = loader.load_optimal_tour(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ac4264da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'eil51',\n",
       " 'dimension': 51,\n",
       " 'coordinates': {1: [37, 52],\n",
       "  2: [49, 49],\n",
       "  3: [52, 64],\n",
       "  4: [20, 26],\n",
       "  5: [40, 30],\n",
       "  6: [21, 47],\n",
       "  7: [17, 63],\n",
       "  8: [31, 62],\n",
       "  9: [52, 33],\n",
       "  10: [51, 21],\n",
       "  11: [42, 41],\n",
       "  12: [31, 32],\n",
       "  13: [5, 25],\n",
       "  14: [12, 42],\n",
       "  15: [36, 16],\n",
       "  16: [52, 41],\n",
       "  17: [27, 23],\n",
       "  18: [17, 33],\n",
       "  19: [13, 13],\n",
       "  20: [57, 58],\n",
       "  21: [62, 42],\n",
       "  22: [42, 57],\n",
       "  23: [16, 57],\n",
       "  24: [8, 52],\n",
       "  25: [7, 38],\n",
       "  26: [27, 68],\n",
       "  27: [30, 48],\n",
       "  28: [43, 67],\n",
       "  29: [58, 48],\n",
       "  30: [58, 27],\n",
       "  31: [37, 69],\n",
       "  32: [38, 46],\n",
       "  33: [46, 10],\n",
       "  34: [61, 33],\n",
       "  35: [62, 63],\n",
       "  36: [63, 69],\n",
       "  37: [32, 22],\n",
       "  38: [45, 35],\n",
       "  39: [59, 15],\n",
       "  40: [5, 6],\n",
       "  41: [10, 17],\n",
       "  42: [21, 10],\n",
       "  43: [5, 64],\n",
       "  44: [30, 15],\n",
       "  45: [39, 10],\n",
       "  46: [32, 39],\n",
       "  47: [25, 32],\n",
       "  48: [25, 55],\n",
       "  49: [48, 28],\n",
       "  50: [56, 37],\n",
       "  51: [30, 40]},\n",
       " 'distance_matrix': array([[ 0., 12., 19., ..., 26., 24., 14.],\n",
       "        [12.,  0., 15., ..., 21., 14., 21.],\n",
       "        [19., 15.,  0., ..., 36., 27., 33.],\n",
       "        ...,\n",
       "        [26., 21., 36., ...,  0., 12., 22.],\n",
       "        [24., 14., 27., ..., 12.,  0., 26.],\n",
       "        [14., 21., 33., ..., 22., 26.,  0.]]),\n",
       " 'optimal_value': 426,\n",
       " 'edge_weight_type': 'EUC_2D'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c346a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data.tsplib_loader import TSPLIBLoader\n",
    "\n",
    "class TSPRLAgent:\n",
    "    \"\"\"Reinforcement learning agent for TSP route construction.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        # extract the test scenerio data\n",
    "        loader = TSPLIBLoader(data_dir = \"../../data/problem_instances\")\n",
    "        instance = config['instance']\n",
    "        data = loader.load_instance(instance)\n",
    "        self.test_data = data\n",
    "        self.distance_matrix = data['distance_matrix']\n",
    "        self.name = data['name']\n",
    "        self.dimension = data['dimension'] \n",
    "        self.coordinates = data['coordinates']\n",
    "        self.optimal_value = data['optimal_value']\n",
    "        \n",
    "        # pull out the RL hyper parameters\n",
    "        self.config = config\n",
    "        self.alpha = config.get('alpha', 0.01)  # Learning rate\n",
    "        self.gamma = config.get('gamma', 0.15)  # Discount factor\n",
    "        self.episodes = config.get('episodes', 1000)\n",
    "        self.reward_type = config.get('reward_type', 1)\n",
    "        self.epsilon_greedy_type = config.get('epsilon_greedy_type',1)\n",
    "\n",
    "        # initialize our Q tables\n",
    "        self.QA = np.zeros([self.dimension, self.dimension]) # Q-value table\n",
    "        self.QB = np.zeros([self.dimension, self.dimension]) # Q-value table\n",
    "        self.done = False\n",
    "        \n",
    "        # # set random seed\n",
    "        # random_seed = 42\n",
    "        # np.random.seed(random_seed)\n",
    "    \n",
    "    def action_space(self, visited):\n",
    "        \"\"\"Return the action space (list of cities that have not been visited).\"\"\"\n",
    "        return [coord for coord in range(self.dimension) if coord not in visited]\n",
    "    def reward(self, current_city, action):\n",
    "        \"\"\"Calculate reward for moving from current_city to next_city.\"\"\"\n",
    "        distance = self.distance_matrix[current_city, action]\n",
    "        \n",
    "        # return the reward type specified in the config (either inverse of distance or negative squared distance)\n",
    "        if self.reward_type == 1:\n",
    "            return 1 / distance\n",
    "        if self.reward_type == 2:\n",
    "            return -distance**2\n",
    "            \n",
    "    def step(self, current_city, action, visited):\n",
    "        \"\"\"Take a step in the environment.\"\"\"\n",
    "        \n",
    "        # compute the reward at our current state and action\n",
    "        reward = self.reward(current_city, action)\n",
    "        \n",
    "        # define the next state\n",
    "        next_city = action\n",
    "        \n",
    "        # compute our list of visited states at from the action\n",
    "        next_visited = visited | {action}\n",
    "        \n",
    "        # if we are at the last city, return to the initial city\n",
    "        if len(next_visited) == self.dimension:\n",
    "            # reward += self.reward(next_city, 0)\n",
    "            self.done= True\n",
    "        return next_city, reward, next_visited\n",
    "    def epsilon_greedy_policy(self, epsilon, current_city, visited):\n",
    "        \"\"\"Select next city using epsilon-greedy policy.\"\"\"\n",
    "        \n",
    "        # compute the action space of remaining cities from the ones we've visited\n",
    "        action_space = self.action_space(visited)\n",
    "        \n",
    "        if np.random.rand() < epsilon:\n",
    "            # Explore - choose a random city\n",
    "            next_city = np.random.choice(action_space)\n",
    "        else:\n",
    "            # Exploit - choose the best known city\n",
    "            next_city = max(action_space, key = lambda a: 0.5* (self.QA[current_city, a] + self.QB[current_city, a]))\n",
    "        return next_city\n",
    "    def compute_epsilon(self, episode):\n",
    "        \"\"\"Compute our epsilon for epsilon greedy double Q-learning\"\"\"\n",
    "        \n",
    "        if self.epsilon_greedy_type == 1:\n",
    "            return 1 - episode / self.episodes\n",
    "        if self.epsilon_greedy_type == 2:\n",
    "            return 1 - (episode / self.episodes)**6\n",
    "        else:\n",
    "            1 - 0.1 * (np.floor(episode/self.episodes))\n",
    "        \n",
    "    def train_episode(self, epsiode_num):\n",
    "        \"\"\"Generate RL epsiode the RL agent.\"\"\"\n",
    "        \n",
    "        # initialize environment\n",
    "        current_city = 0\n",
    "        visited = frozenset({current_city})\n",
    "        self.done = False\n",
    "        epsilon = self.compute_epsilon(epsiode_num)\n",
    "        \n",
    "        # initialize Q value for all final states\n",
    "        for state in range(1,self.dimension):\n",
    "            self.QA[state, 0] = self.reward(state, 0)\n",
    "            self.QB[state, 0] = self.reward(state, 0)\n",
    "        \n",
    "        # loop until episode is done\n",
    "        while not self.done:\n",
    "            \n",
    "            # pick action using epsilon-greedy policy\n",
    "            action = self.epsilon_greedy_policy(epsilon, current_city, visited)\n",
    "            \n",
    "            # proceed to next state\n",
    "            next_city, reward, next_visited = self.step(current_city, action, visited)\n",
    "            \n",
    "            # update Q-values\n",
    "            if len(next_visited) == self.dimension:\n",
    "                \n",
    "                random_choice = np.random.rand()\n",
    "                # if random_choice < 0.5:\n",
    "                self.QA[(current_city, action)] = self.QA[current_city, action] + self.alpha * (reward + self.gamma * (self.QB[next_city, 0]) - self.QA[current_city, action])\n",
    "                # else:\n",
    "                self.QB[(current_city, action)] = self.QB[current_city, action] + self.alpha * (reward + self.gamma * (self.QA[next_city, 0]) - self.QB[current_city, action])\n",
    "                self.done = True\n",
    "            else:\n",
    "                random_choice = np.random.rand()\n",
    "                # if random_choice < 0.5:\n",
    "                self.QA[(current_city, action)] = self.QA[current_city, action] + self.alpha * (reward + self.gamma * max(self.QB[next_city, a] for a in self.action_space(next_visited)) - self.QA[current_city, action])\n",
    "                # else:\n",
    "                self.QB[(current_city, action)] = self.QB[current_city, action] + self.alpha * (reward + self.gamma * max(self.QA[next_city, a] for a in self.action_space(next_visited)) - self.QB[current_city, action])\n",
    "            \n",
    "            # increment state\n",
    "            current_city = next_city\n",
    "            visited = next_visited\n",
    "\n",
    "            \n",
    "    def train(self):\n",
    "        \"\"\"Train the RL agent.\"\"\"\n",
    "        \n",
    "        # perform Q-learning for the number of episodes specified\n",
    "        for episode in range(self.episodes):\n",
    "            self.train_episode(episode)\n",
    "    \n",
    "    \n",
    "    def optimal_route(self):\n",
    "        \"\"\"Construct optimal route using trained policy.\"\"\"\n",
    "        \n",
    "        # initialize enviorment\n",
    "        current_city = 0\n",
    "        visited = frozenset({current_city})\n",
    "        route = [current_city]\n",
    "        self.done = False\n",
    "        cost = 0\n",
    "        \n",
    "        # Loop through the states selecting the action that maximizes our learned Q functions\n",
    "        while not self.done:\n",
    "            action_space = self.action_space(visited)\n",
    "            next_city = max(action_space, key = lambda a: 0.5* (self.QA[current_city, a] + self.QB[current_city, a]))\n",
    "            route.append(next_city)\n",
    "            visited = visited | {next_city}\n",
    "            cost += self.distance_matrix[current_city, next_city]\n",
    "            current_city = next_city\n",
    "            if len(visited) == self.dimension:\n",
    "                route.append(0)  # Return to starting city\n",
    "                cost += self.distance_matrix[next_city, 0]\n",
    "                self.done = True\n",
    "                \n",
    "        return cost,route\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "1efd145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 8862.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "instances = ['eil51', 'berlin52', 'st70', 'eil76', 'kroA100', 'pr107']\n",
    "instance = 'berlin52'\n",
    "\n",
    "agent_config = {\n",
    "    'alpha': 0.01,\n",
    "    'gamma': 0.01,\n",
    "    'episodes': 10000,\n",
    "    'instance' : instance,\n",
    "    'reward_type' : 1,\n",
    "    'epsilon_greedy_type' : 1\n",
    "}\n",
    "agent = TSPRLAgent(agent_config)\n",
    "agent.train()\n",
    "cost, constructed_route = agent.optimal_route()\n",
    "print(\"Cost:\", cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "17f8baf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
      "[1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
      "[1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50]\n",
      "[1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50]\n",
      "[1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50]\n",
      "[1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "[1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49]\n",
      "[1, 2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49]\n",
      "[1, 2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 12, 13, 15, 17, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 12, 13, 15, 17, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 42, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 13, 15, 17, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 42, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 13, 15, 17, 19, 20, 22, 23, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 42, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 15, 17, 19, 20, 22, 23, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 42, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 15, 19, 20, 22, 23, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 42, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 15, 19, 20, 22, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 42, 44, 48, 49]\n",
      "[1, 2, 4, 6, 8, 9, 10, 15, 19, 20, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 42, 44, 48, 49]\n",
      "[1, 2, 4, 8, 9, 10, 15, 19, 20, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 42, 44, 48, 49]\n",
      "[1, 2, 4, 8, 9, 10, 15, 19, 20, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 44, 48, 49]\n",
      "[1, 2, 4, 8, 9, 10, 15, 19, 20, 28, 29, 32, 33, 34, 35, 37, 38, 39, 44, 48, 49]\n",
      "[1, 2, 4, 8, 9, 15, 19, 20, 28, 29, 32, 33, 34, 35, 37, 38, 39, 44, 48, 49]\n",
      "[1, 2, 4, 8, 9, 15, 19, 20, 28, 29, 32, 33, 34, 35, 38, 39, 44, 48, 49]\n",
      "[1, 2, 4, 9, 15, 19, 20, 28, 29, 32, 33, 34, 35, 38, 39, 44, 48, 49]\n",
      "[1, 2, 4, 9, 15, 19, 20, 28, 29, 32, 33, 34, 35, 38, 39, 44, 48]\n",
      "[1, 2, 4, 9, 15, 19, 20, 28, 29, 32, 34, 35, 38, 39, 44, 48]\n",
      "[1, 2, 4, 9, 15, 19, 20, 28, 32, 34, 35, 38, 39, 44, 48]\n",
      "[1, 2, 4, 15, 19, 20, 28, 32, 34, 35, 38, 39, 44, 48]\n",
      "[1, 2, 4, 15, 19, 20, 28, 32, 34, 35, 38, 39, 44]\n",
      "[1, 2, 15, 19, 20, 28, 32, 34, 35, 38, 39, 44]\n",
      "[1, 2, 19, 20, 28, 32, 34, 35, 38, 39, 44]\n",
      "[2, 19, 20, 28, 32, 34, 35, 38, 39, 44]\n",
      "[2, 19, 20, 32, 34, 35, 38, 39, 44]\n",
      "[2, 19, 32, 34, 35, 38, 39, 44]\n",
      "[2, 32, 34, 35, 38, 39, 44]\n",
      "[2, 32, 35, 38, 39, 44]\n",
      "[2, 32, 38, 39, 44]\n",
      "[32, 38, 39, 44]\n",
      "[32, 39, 44]\n",
      "[39, 44]\n",
      "[39]\n",
      "Cost: 579.0\n",
      "Constructed route: [0, 21, 27, 30, 25, 7, 47, 5, 26, 50, 45, 11, 46, 3, 16, 36, 14, 43, 41, 18, 40, 12, 24, 13, 17, 23, 22, 6, 42, 31, 10, 37, 8, 49, 33, 29, 9, 48, 4, 15, 1, 28, 20, 19, 34, 35, 2, 38, 32, 44, 39, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost, constructed_route = agent.optimal_route()\n",
    "print(\"Cost:\", cost)\n",
    "print(\"Constructed route:\", constructed_route)\n",
    "sorted(constructed_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f458c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 22, 8, 26, 31, 28, 3, 36, 35, 20, 2, 29, 21, 16, 50, 34, 30, 9, 49, 10, 39, 33, 45, 15, 44, 42, 40, 19, 41, 13, 25, 14, 24, 43, 7, 23, 48, 6, 27, 51, 46, 12, 47, 18, 4, 17, 37, 5, 38, 11, 32]\n"
     ]
    }
   ],
   "source": [
    "print(tour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c9906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426.0"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tour = loader.load_optimal_tour(instance)\n",
    "data = loader.load_instance(instance)\n",
    "instances = ['eil51', 'berlin52', 'st70', 'eil76', 'kroA100', 'pr107']\n",
    "\n",
    "cost = 0\n",
    "for i in range(len(tour)-1):\n",
    "    cost += data['distance_matrix'][tour[i]-1, tour[i+1]-1]\n",
    "cost += data['distance_matrix'][tour[-1]-1, tour[0]-1]\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "627bbf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.08333333 0.05263158 0.03225806 0.04545455 0.05882353\n",
      " 0.04347826 0.08333333 0.04166667 0.02941176 0.08333333 0.04761905\n",
      " 0.02380952 0.03703704 0.02777778 0.05263158 0.03225806 0.03571429\n",
      " 0.02173913 0.04761905 0.03703704 0.14285714 0.04545455 0.03448276\n",
      " 0.03030303 0.05263158 0.125      0.0625     0.04761905 0.03030303\n",
      " 0.05882353 0.16666667 0.02325581 0.03225806 0.03703704 0.03225806\n",
      " 0.03333333 0.05263158 0.02325581 0.01785714 0.02272727 0.02222222\n",
      " 0.02941176 0.02631579 0.02380952 0.07142857 0.04347826 0.08333333\n",
      " 0.03846154 0.04166667 0.07142857]\n"
     ]
    }
   ],
   "source": [
    "print(agent.QA[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9384a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_set = frozenset({0, 1, 2})\n",
    "frozen_set = frozen_set | {3}\n",
    "test = {}\n",
    "test[(0, frozen_set, 1)] = \"test_value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11f72462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  6.,  8., 10., 10.],\n",
       "       [ 4.,  0.,  4., 11., 19.],\n",
       "       [13., 16.,  0., 18.,  5.],\n",
       "       [11., 13.,  8.,  0., 17.],\n",
       "       [10., 12.,  4., 19.,  0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "D = np.random.randint(1, 20, size=(5, 5)).astype(float)\n",
    "np.fill_diagonal(D, 0)\n",
    "\n",
    "# Ensure asymmetry\n",
    "for i in range(5):\n",
    "    for j in range(i+1, 5):\n",
    "        D[i, j] += np.random.randint(0, 5)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cb119a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited_mask = 1 << 0\n",
    "visited_mask | (1 << 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcad84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Instead of using the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
